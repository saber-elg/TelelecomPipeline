{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046b0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Reporting\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec60e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "global_invoice = spark.read.parquet(\"invoice\")\n",
    "\n",
    "sortedCustomersByInvoice = (global_invoice\n",
    "    .filter(\"data_total > 0\")  # Filter for customers with data usage\n",
    "    .groupBy(\"customer_id\")\n",
    "    .agg(F.sum(\"data_total\").alias(\"total_data_usage\"),\n",
    "         F.sum(\"amount_due\").alias(\"total_amount_due\"))\n",
    "    .orderBy(F.desc(\"total_data_usage\")))\n",
    "\n",
    "# Write the results\n",
    "sortedCustomersByInvoice.write.mode(\"overwrite\").option(\"header\", True).csv(\"report/sortedCustomersByInvoices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7eebd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenus TTC par plan tarifaire \n",
    "\n",
    "global_invoice = spark.read.parquet(\"invoice\")\n",
    "rev_plan = (global_invoice\n",
    "            .groupBy(\"rate_plan_id\")\n",
    "            .agg(F.sum(\"amount_due\").alias(\"revenue_TTC\"))\n",
    "            .orderBy(F.desc(\"revenue_TTC\")))\n",
    "\n",
    "rev_plan.write.mode(\"overwrite\").option(\"header\", True).csv(\"report/revenueByPlan.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc565ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_region = (global_invoice\n",
    "    .groupBy(\"region\", \"rate_plan_id\")\n",
    "    .agg(F.sum(\"amount_due\").alias(\"revenue_TTC\"))\n",
    "    .orderBy(\"region\", F.desc(\"revenue_TTC\"))\n",
    ")\n",
    "\n",
    "plan_region.write.mode(\"overwrite\")\\\n",
    "    .option(\"header\", True)\\\n",
    "    .csv(\"report/planByRegion.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ca6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Parquet file\n",
    "rated = spark.read.parquet(\"rated_data/\")\n",
    "\n",
    "# Calculate total cost per product code\n",
    "product_costs = (\n",
    "    rated.filter(\"rating_status = 'rated'\")\n",
    "    .groupBy(\"product_code\")\n",
    "    .agg(\n",
    "        (F.floor(F.sum(\"cost\") * 100) / 100).alias(\"total_cost\"),  # Floored to 2 decimals\n",
    "        F.count(\"*\").alias(\"record_count\"),\n",
    "        F.avg(\"cost\").alias(\"avg_cost_per_record\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"total_cost\"))\n",
    ")\n",
    "\n",
    "# Save results to CSV\n",
    "(\n",
    "    product_costs\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"header\", True)\n",
    "    .csv(\"report/product_cost_analysis.csv\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
